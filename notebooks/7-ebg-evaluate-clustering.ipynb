{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pandas as pd\n",
    "from random import sample\n",
    "from numpy.random import uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import BallTree\n",
    "\n",
    "\n",
    "def hopkins(data_frame: Union[np.ndarray, pd.DataFrame], sampling_size: int) -> float:\n",
    "    \"\"\"Assess the clusterability of a dataset. A score between 0 and 1, a score around 0.5 express\n",
    "    no clusterability and a score tending to 0 express a high cluster tendency.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn import datasets\n",
    "    >>> from pyclustertend import hopkins\n",
    "    >>> X = datasets.load_iris().data\n",
    "    >>> hopkins(X,150)\n",
    "    0.16\n",
    "    \"\"\"\n",
    "\n",
    "    if type(data_frame) == np.ndarray:\n",
    "        data_frame = pd.DataFrame(data_frame)\n",
    "\n",
    "    data_frame_sample = sample_observation_from_dataset(data_frame, sampling_size)\n",
    "\n",
    "    sample_distances_to_nearest_neighbours = get_distance_sample_to_nearest_neighbours(\n",
    "        data_frame, data_frame_sample\n",
    "    )\n",
    "\n",
    "    uniformly_selected_observations_df = simulate_df_with_same_variation(\n",
    "        data_frame, sampling_size\n",
    "    )\n",
    "\n",
    "    df_distances_to_nearest_neighbours = get_nearest_sample(\n",
    "        data_frame, uniformly_selected_observations_df\n",
    "    )\n",
    "\n",
    "    x = sum(sample_distances_to_nearest_neighbours)\n",
    "    y = sum(df_distances_to_nearest_neighbours)\n",
    "\n",
    "    if x + y == 0:\n",
    "        raise Exception(\"The denominator of the hopkins statistics is null\")\n",
    "\n",
    "    return x / (x + y)[0]\n",
    "\n",
    "\n",
    "def get_nearest_sample(df: pd.DataFrame, uniformly_selected_observations: pd.DataFrame):\n",
    "    tree = BallTree(df, leaf_size=2)\n",
    "    dist, _ = tree.query(uniformly_selected_observations, k=1)\n",
    "    uniformly_df_distances_to_nearest_neighbours = dist\n",
    "    return uniformly_df_distances_to_nearest_neighbours\n",
    "\n",
    "\n",
    "def simulate_df_with_same_variation(\n",
    "    df: pd.DataFrame, sampling_size: int\n",
    ") -> pd.DataFrame:\n",
    "    max_data_frame = df.max()\n",
    "    min_data_frame = df.min()\n",
    "    uniformly_selected_values_0 = np.random.uniform(\n",
    "        min_data_frame[0], max_data_frame[0], sampling_size\n",
    "    )\n",
    "    uniformly_selected_values_1 = np.random.uniform(\n",
    "        min_data_frame[1], max_data_frame[1], sampling_size\n",
    "    )\n",
    "    uniformly_selected_observations = np.column_stack(\n",
    "        (uniformly_selected_values_0, uniformly_selected_values_1)\n",
    "    )\n",
    "    if len(max_data_frame) >= 2:\n",
    "        for i in range(2, len(max_data_frame)):\n",
    "            uniformly_selected_values_i = np.random.uniform(\n",
    "                min_data_frame[i], max_data_frame[i], sampling_size\n",
    "            )\n",
    "            to_stack = (uniformly_selected_observations, uniformly_selected_values_i)\n",
    "            uniformly_selected_observations = np.column_stack(to_stack)\n",
    "    uniformly_selected_observations_df = pd.DataFrame(uniformly_selected_observations)\n",
    "    return uniformly_selected_observations_df\n",
    "\n",
    "\n",
    "def get_distance_sample_to_nearest_neighbours(df: pd.DataFrame, data_frame_sample):\n",
    "    tree = BallTree(df, leaf_size=2)\n",
    "    dist, _ = tree.query(data_frame_sample, k=2)\n",
    "    data_frame_sample_distances_to_nearest_neighbours = dist[:, 1]\n",
    "    return data_frame_sample_distances_to_nearest_neighbours\n",
    "\n",
    "\n",
    "def sample_observation_from_dataset(df, sampling_size: int):\n",
    "    if sampling_size > df.shape[0]:\n",
    "        raise Exception(\"The number of sample of sample is bigger than the shape of D\")\n",
    "    data_frame_sample = df.sample(n=sampling_size)\n",
    "    return data_frame_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hopkins_statistic(X):\n",
    "    sample_size = int(X.shape[0]*0.05) #0.05 (5%) based on paper by Lawson and Jures\n",
    "    \n",
    "    \n",
    "    #a uniform random sample in the original data space\n",
    "    X_uniform_random_sample = uniform(X.min(axis=0), X.max(axis=0) ,(sample_size , X.shape[1]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #a random sample of size sample_size from the original data X\n",
    "    random_indices=sample(range(0, X.shape[0], 1), sample_size)\n",
    "    X_sample = X[random_indices]\n",
    "   \n",
    "    \n",
    "    #initialise unsupervised learner for implementing neighbor searches\n",
    "    neigh = NearestNeighbors(n_neighbors=2)\n",
    "    nbrs=neigh.fit(X)\n",
    "    \n",
    "    #u_distances = nearest neighbour distances from uniform random sample\n",
    "    u_distances , u_indices = nbrs.kneighbors(X_uniform_random_sample , n_neighbors=2)\n",
    "    u_distances = u_distances[: , 0] #distance to the first (nearest) neighbour\n",
    "    \n",
    "    #w_distances = nearest neighbour distances from a sample of points from original data X\n",
    "    w_distances , w_indices = nbrs.kneighbors(X_sample , n_neighbors=2)\n",
    "    #distance to the second nearest neighbour (as the first neighbour will be the point itself, with distance = 0)\n",
    "    w_distances = w_distances[: , 1]\n",
    "    \n",
    " \n",
    "    \n",
    "    u_sum = np.sum(u_distances)\n",
    "    w_sum = np.sum(w_distances)\n",
    "    \n",
    "    #compute and return hopkins' statistic\n",
    "    H = u_sum/ (u_sum + w_sum)\n",
    "    return H\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = pd.read_pickle(\"../data/processed/graph_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(embeddings.graph_embedding.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9543684260917044"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_stat = hopkins_statistic(X)\n",
    "h_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import OPTICS, cluster_optics_dbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ethan\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_optics.py:804: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OPTICS(min_samples=20)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clust = OPTICS(min_samples=20)\n",
    "clust.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = hopkins(scale(X), X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024958128495815843"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1621744034748126"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = hdbscan.HDBSCAN(min_cluster_size=37, metric='manhattan')\n",
    "h.fit(X)\n",
    "metrics.silhouette_score(X, h.labels_, metric='manhattan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    576\n",
       " 0    100\n",
       " 1     84\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(h.labels_)\n",
    "s.value_counts()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bdb1f293a72cda3337025d9d00554afb1343cd7218118617db03a8cb5103ebd2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
